import os
import time
import re

# [New] å¼•å…¥æ··åˆæ£€ç´¢ç»„ä»¶
from langchain_qdrant import QdrantVectorStore, FastEmbedSparse, RetrievalMode
from langchain_community.embeddings import XinferenceEmbeddings
from qdrant_client import QdrantClient
from reranker import XinferenceRerank

# æ™ºèƒ½å¯¼å…¥ Retriever
try:
    from langchain.retrievers import ContextualCompressionRetriever
except ImportError:
    from langchain_classic.retrievers import ContextualCompressionRetriever

# é…ç½®
XINFERENCE_URL = os.getenv("XINFERENCE_SERVER_URL", "http://192.168.123.113:9997")
EMBED_MODEL = os.getenv("EMBEDDING_MODEL_UID", "bge-m3")
RERANK_MODEL = os.getenv("RERANK_MODEL_UID", "bge-reranker-v2-m3")
QDRANT_URL = os.getenv("QDRANT_URL", "http://qdrant:6333")
COLLECTION_NAME = os.getenv("COLLECTION_NAME", "story_knowledge_base")

def get_snippet(text, query, window=100):
    clean_query = re.sub(r'[?ï¼Ÿ!ï¼,ï¼Œ.ã€‚]', '', query)
    clean_text = text.replace('\n', ' ')
    if clean_query in clean_text:
        idx = clean_text.find(clean_query)
        start = max(0, idx - window)
        end = min(len(clean_text), idx + len(clean_query) + window)
        return f"...{clean_text[start:end]}...", True
    else:
        return f"{clean_text[:400]}...", False

def main():
    print(f"\nâš”ï¸ å¯åŠ¨æ··åˆæ£€ç´¢è¯„ä¼° (Hybrid Search Mode)...")
    
    client = QdrantClient(url=QDRANT_URL)
    
    # 1. åˆå§‹åŒ–åŒè·¯ Embedding (å¿…é¡»ä¸ Ingest æ—¶ä¸€è‡´)
    dense_embeddings = XinferenceEmbeddings(server_url=XINFERENCE_URL, model_uid=EMBED_MODEL)
    sparse_embeddings = FastEmbedSparse(model_name="Qdrant/bm25")
    
    # 2. åˆå§‹åŒ–æ··åˆ VectorStore
    vector_store = QdrantVectorStore(
        client=client, 
        collection_name=COLLECTION_NAME, 
        embedding=dense_embeddings,
        sparse_embedding=sparse_embeddings, # å…³é”®ï¼šæ³¨å…¥ç¨€ç–æ¨¡å‹
        retrieval_mode=RetrievalMode.HYBRID # å…³é”®ï¼šå¼€å¯æ··åˆæ¨¡å¼
    )
    
    # 3. ç²—æ’é…ç½® (Hybrid Recall)
    # æ··åˆæ£€ç´¢ä¼šåŒæ—¶è·‘å‘é‡å’Œå…³é”®è¯ï¼Œç„¶ååœ¨ Qdrant å†…éƒ¨åš RRF èåˆ
    base_retriever = vector_store.as_retriever(search_kwargs={"k": 50})

    # 4. ç²¾æ’é…ç½® (Rerank)
    reranker = XinferenceRerank(
        url=f"{XINFERENCE_URL.rstrip('/')}/v1/rerank",
        model_uid=RERANK_MODEL,
        top_n=5
    )

    # 5. ç®¡é“ç»„è£…
    compression_retriever = ContextualCompressionRetriever(
        base_compressor=reranker,
        base_retriever=base_retriever
    )

    while True:
        print("\n" + "="*60)
        query = input("é—®é¢˜ (è¾“å…¥ 'q' é€€å‡º): ")
        if query.lower() in ['q', 'exit']: break
        
        start_t = time.time()
        print(f"ğŸ” [Hybrid] Qdrant(Dense+Sparse) -> [Rerank] Xinference...")
        
        try:
            results = compression_retriever.invoke(query)
            cost_t = time.time() - start_t
            
            print(f"\nè€—æ—¶ {cost_t:.2f}s | å¬å› {len(results)} æ¡ç»“æœ:")
            print("-" * 60)
            
            for i, doc in enumerate(results):
                score = doc.metadata.get("relevance_score", 0)
                scene = doc.metadata.get("scene", "æœªçŸ¥")
                
                snippet, is_hit = get_snippet(doc.page_content, query)
                hit_mark = "ç²¾ç¡®å‘½ä¸­" if is_hit else "è¯­ä¹‰/RRFç›¸å…³"
                
                print(f"Rank #{i+1} | Score: {score:.4f} | {hit_mark}")
                print(f"   åœºæ™¯: {scene}")
                print(f"   å†…å®¹: {snippet}")
                print("-" * 60)
                
        except Exception as e:
            print(f"æ£€ç´¢å¤±è´¥: {e}")

if __name__ == "__main__":
    main()