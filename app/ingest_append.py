import json
import os
import uuid
import warnings
from typing import List, Tuple

# å±è”½è­¦å‘Š
warnings.filterwarnings("ignore")

# æ ¸å¿ƒç»„ä»¶
from langchain_qdrant import QdrantVectorStore, FastEmbedSparse, RetrievalMode
from qdrant_client import QdrantClient
from langchain_community.embeddings import XinferenceEmbeddings
from langchain_core.documents import Document

# --- é…ç½® (å¿…é¡»ä¸åŸ ingest.py ä¿æŒå®Œå…¨ä¸€è‡´) ---
XINFERENCE_URL = os.getenv("XINFERENCE_SERVER_URL", "http://192.168.123.113:9997")
EMBED_MODEL = os.getenv("EMBEDDING_MODEL_UID", "bge-m3")
QDRANT_URL = os.getenv("QDRANT_URL", "http://qdrant:6333")
COLLECTION_NAME = os.getenv("COLLECTION_NAME", "story_knowledge_base")
SPARSE_VECTOR_NAME = "langchain-sparse" # å¿…é¡»ä¸å»ºè¡¨æ—¶ä¸€è‡´

def resolve_default_append_path() -> str:
    """
    é€‰æ‹©ä¸€ä¸ªå®é™…å­˜åœ¨çš„é»˜è®¤æ•°æ®è·¯å¾„ï¼Œé¿å…ç”¨æˆ·ç›´æ¥å›è½¦åæŒ‡å‘ä¸å­˜åœ¨çš„æ–‡ä»¶ã€‚
    ä¼˜å…ˆä½¿ç”¨ç¯å¢ƒå˜é‡ï¼Œå…¶æ¬¡å°è¯•å¢é‡ç¤ºä¾‹æ–‡ä»¶ï¼Œå†å›é€€åˆ°å½“å‰å¯ç”¨çš„å…¨é‡æ–‡ä»¶ã€‚
    """
    candidates = [
        os.getenv("APPEND_DATA_FILE", "").strip(),
        "/data/timeline_flow_optimized.json",
        "data/timeline_flow_optimized.json",
    ]
    for path in candidates:
        if path and os.path.exists(path):
            return path
    # å¦‚æœéƒ½ä¸å­˜åœ¨ï¼Œä¿ç•™æ—§é»˜è®¤å€¼ï¼Œåç»­ä¼šæœ‰æ˜ç¡®æŠ¥é”™
    return "/data/new_stories.json"

def load_data_with_ids(file_path: str) -> Tuple[List[Document], List[str]]:
    """
    åŠ è½½æ•°æ®é€»è¾‘ä¿æŒä¸å˜ï¼Œç¡®ä¿ ID ç”Ÿæˆç®—æ³•ä¸€è‡´ (UUID5)ï¼Œ
    è¿™æ ·å¦‚æœæ•°æ®é‡å¤ï¼ŒQdrant ä¼šæ‰§è¡Œæ›´æ–°è€Œä¸æ˜¯æ’å…¥é‡å¤é¡¹ã€‚
    """
    if not os.path.exists(file_path):
        raise FileNotFoundError(f"æ‰¾ä¸åˆ°æ–‡ä»¶: {file_path}")

    with open(file_path, 'r', encoding='utf-8') as f:
        data = json.load(f)
    if isinstance(data, dict): data = [data]
    
    docs = []
    ids = []
    
    print(f"ğŸ“Š æ­£åœ¨è§£æ {len(data)} æ¡æ–°æ•°æ®...")

    def _normalize_text(item: dict) -> str:
        """ä¼˜å…ˆä½¿ç”¨æ–°æ ¼å¼é‡Œçš„ text å­—æ®µï¼Œä¸å­˜åœ¨æ—¶å›é€€åˆ° script åˆ—è¡¨ã€‚"""
        if item.get("text"):
            return item["text"]
        script = item.get("script", [])
        if isinstance(script, list) and script:
            lines = []
            for turn in script:
                speaker = turn.get("c")
                text = turn.get("t", "")
                prefix = f"{speaker}: " if speaker else ""
                lines.append(f"{prefix}{text}")
            return "\n".join(lines)
        return item.get("content", "")

    for order_idx, item in enumerate(data):
        ctx = item.get("ctx") or {}
        stats = item.get("stats") or {}
        timeline = item.get("timeline") or {}

        raw_id = item.get("id") or item.get("scene")
        if raw_id:
            # åªè¦ ID ç›¸åŒï¼Œç”Ÿæˆçš„ UUID å°±ç›¸åŒ -> è¦†ç›–æ—§æ•°æ®
            point_id = str(uuid.uuid5(uuid.NAMESPACE_DNS, str(raw_id)))
        else:
            point_id = str(uuid.uuid4())
            raw_id = ""

        processed_meta = {
            "scene": item.get("scene") or raw_id or "unknown",
            "id": raw_id,
            "source": item.get("src", ""),
            "order": order_idx,
            "chars": ctx.get("chars") or [],
            "voices": ctx.get("voices") or [],
            "loc": ctx.get("loc"),
            "time": ctx.get("time"),
            "bgm": ctx.get("bgm", ""),
            "type": ctx.get("type", ""),
            "stats": stats,
            "timeline": timeline,
            "act": ctx.get("act") or {},
            "emo": ctx.get("emo") or {},
            "state_act": ctx.get("state_act") or {},
            "state_emo": ctx.get("state_emo") or {},
            "state": ctx.get("state"),
            "weather": ctx.get("weather"),
            "merged_from": item.get("merged_from") or [],
            "script": item.get("script", []),
        }

        content = _normalize_text(item)
        ids.append(point_id)
        docs.append(Document(page_content=content, metadata=processed_meta))
        
    return docs, ids

def main():
    print(f"\nğŸš€ å¯åŠ¨å¢é‡å…¥åº“æ¨¡å¼ (Incremental Ingestion)...")
    print(f"ğŸ¯ ç›®æ ‡é›†åˆ: {COLLECTION_NAME}")

    client = QdrantClient(url=QDRANT_URL)
    
    # 1. å®‰å…¨æ£€æŸ¥ï¼šç¡®ä¿é›†åˆå­˜åœ¨
    if not client.collection_exists(COLLECTION_NAME):
        print(f"âŒ é”™è¯¯: é›†åˆ '{COLLECTION_NAME}' ä¸å­˜åœ¨ï¼")
        print("   è¯·å…ˆè¿è¡Œ ingest.py è¿›è¡Œåˆå§‹åŒ–å»ºè¡¨ã€‚")
        return

    # 2. è¾“å…¥æ–°æ•°æ®è·¯å¾„
    default_path = resolve_default_append_path()
    file_path = input(f"ğŸ“‚ è¯·è¾“å…¥æ–°æ•°æ®æ–‡ä»¶è·¯å¾„ [é»˜è®¤: {default_path}]: ").strip()
    if not file_path:
        file_path = default_path
    
    if not os.path.exists(file_path):
        print(f"âŒ æ‰¾ä¸åˆ°æ–‡ä»¶: {file_path}")
        print("   è¯·ç¡®è®¤è·¯å¾„ï¼Œæˆ–è®¾ç½® APPEND_DATA_FILE æŒ‡å‘æ­£ç¡®çš„æ•°æ®æ–‡ä»¶ã€‚")
        return

    # 3. åˆå§‹åŒ–æ¨¡å‹ (Dense + Sparse)
    print("ğŸ”Œ åˆå§‹åŒ– Embeddings (Xinference + FastEmbed)...")
    dense_embeddings = XinferenceEmbeddings(server_url=XINFERENCE_URL, model_uid=EMBED_MODEL)
    sparse_embeddings = FastEmbedSparse(model_name="Qdrant/bm25")

    # 4. åŠ è½½æ–°æ•°æ®
    try:
        docs, ids = load_data_with_ids(file_path)
    except Exception as e:
        print(f"âŒ è¯»å–æ•°æ®å¤±è´¥: {e}")
        return

    # 5. è¿æ¥ VectorStore (æ³¨æ„ï¼šè¿™é‡Œä¸åˆ›å»ºé›†åˆï¼Œåªè¿æ¥)
    vector_store = QdrantVectorStore(
        client=client, 
        collection_name=COLLECTION_NAME,
        embedding=dense_embeddings,
        sparse_embedding=sparse_embeddings,
        sparse_vector_name=SPARSE_VECTOR_NAME,
        retrieval_mode=RetrievalMode.HYBRID
    )
    
    print(f"ğŸŒŠ æ­£åœ¨è¿½åŠ /æ›´æ–° {len(docs)} æ¡æ•°æ®åˆ° Qdrant...")
    
    # 6. æ‰§è¡Œè¿½åŠ  (Add Documents)
    # Qdrant é»˜è®¤è¡Œä¸ºï¼šå¦‚æœ ID å­˜åœ¨åˆ™ Updateï¼Œä¸å­˜åœ¨åˆ™ Insert
    vector_store.add_documents(documents=docs, ids=ids)
    
    print(f"âœ… å¢é‡å…¥åº“å®Œæˆï¼")
    print(f"ğŸ’¡ æç¤º: æ–°æ•°æ®å·²ç«‹å³å¯è¢«æ£€ç´¢ã€‚")

if __name__ == "__main__":
    main()
